{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "democratic-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.layers import Conv1D , Dropout , Flatten , MaxPooling1D, Dense, Input, BatchNormalization\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model , load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "\n",
    "from astroNN.gaia import mag_to_fakemag\n",
    "from astroNN.gaia import fakemag_to_logsol\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import h5py\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "possible-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpectrumParallax(dim_t , dim_n, dropout_iterations = 100): \n",
    "    \"\"\"\n",
    "    INPUT: \n",
    "    dim_t - number of time steps of spectrum \n",
    "    dim_n - number of features of spectrum\n",
    "    \"\"\"\n",
    "    \n",
    "    #SPECTRUM TO LUINOSITY\n",
    "    dim_1 = 1 # number of corrected magnitude for one example \n",
    "    units = 1 #number of final output for one example\n",
    "    \n",
    "    inputs_spectra = Input(shape=(dim_t, dim_n), name=\"pseudo-lum-input\") \n",
    "    inputs_mag = Input(shape=(dim_1,), name=\"K_mag\")\n",
    "    inputs_error_paralaje = Input(shape=(dim_1,), name=\"error_paralaje\")\n",
    "    inputs_offset = Input(shape=(3,), name=\"offset-input\")\n",
    "    print(\"inputs_mag: \",inputs_mag)\n",
    "    print(\"inputs_error_paralaje: \",inputs_error_paralaje)\n",
    "    \n",
    "    \n",
    "    #x_parallax_list = []\n",
    "    \n",
    "    #for i in range(droput_iterations):\n",
    "    x_parallax = Conv1D(filters=2, kernel_size=3, activation='relu')(inputs_spectra)\n",
    "    x_parallax = BatchNormalization()(x_parallax)\n",
    "    x_parallax = MaxPooling1D(pool_size=2)(x_parallax)\n",
    "    x_parallax = Dropout(0.3)(x_parallax, training=True)\n",
    "\n",
    "    x_parallax = Conv1D(filters=4, kernel_size=3, activation='relu')(x_parallax)\n",
    "    x_parallax = BatchNormalization()(x_parallax)\n",
    "    x_parallax = MaxPooling1D(pool_size=2)(x_parallax)\n",
    "    x_parallax = Dropout(0.3)(x_parallax, training=True)\n",
    "\n",
    "    x_parallax = Flatten()(x_parallax)\n",
    "    x_parallax = Dense(128, activation='relu')(x_parallax)\n",
    "    x_parallax = Dropout(0.3)(x_parallax, training=True)\n",
    "        \n",
    "    x_parallax = Dense(64, activation='relu')(x_parallax) \n",
    "    x_parallax = Dropout(0.3)(x_parallax, training=True)\n",
    "    x_parallax = Dense(32, activation='relu')(x_parallax)\n",
    "    x_parallax = Dropout(0.3)(x_parallax, training=True)\n",
    "    x_parallax = Dense(units, activation='softplus', name=\"pseudo-lum\")(x_parallax) \n",
    "    \n",
    "    \n",
    "    #Functions\n",
    "    outputs_parallax = Lambda(lambda function: tf.math.multiply(function[0], tf.math.pow(10., \n",
    "                              tf.math.multiply(-0.2, function[1]))),\n",
    "                              name='parallax')([x_parallax, inputs_mag])\n",
    "    \n",
    "\n",
    "    #Model setup\n",
    "    model =  Model(inputs = [inputs_spectra,inputs_mag],outputs = [outputs_parallax])\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "steady-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load of the data\n",
    "\n",
    "with h5py.File('train_set_gaiaedr3_apogeedr16_1.h5','r') as F:  \n",
    "    parallax = np.array(F['parallax'])\n",
    "    parallax_error = np.array(F['parallax_err'])\n",
    "    spectra = np.array(F['spectra'])\n",
    "    Kmag = np.array(F['corrected_K'])\n",
    "    \n",
    "idx = []\n",
    "for i in range(len(parallax)):\n",
    "    idx.append(i)\n",
    "random.seed(10)\n",
    "random.shuffle(idx)\n",
    "\n",
    "parallax = parallax[idx]\n",
    "parallax_error = parallax_error[idx]\n",
    "spectra = spectra[idx]\n",
    "Kmag = Kmag[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "packed-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(spectra, axis = 2)\n",
    "Y = np.expand_dims(parallax, axis = 1)\n",
    "K_mag = np.expand_dims(Kmag, axis = 1)\n",
    "Y_error = np.expand_dims(parallax_error, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advisory-funds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13976, 7514, 1), (13976, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acting-flavor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_mag:  KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='K_mag'), name='K_mag', description=\"created by layer 'K_mag'\")\n",
      "inputs_error_paralaje:  KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='error_paralaje'), name='error_paralaje', description=\"created by layer 'error_paralaje'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "pseudo-lum-input (InputLayer)   [(None, 7514, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 7512, 2)      8           pseudo-lum-input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 7512, 2)      8           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 3756, 2)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 3754, 4)      28          max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 3754, 4)      16          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 1877, 4)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7508)         0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          961152      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pseudo-lum (Dense)              (None, 1)            33          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "K_mag (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "parallax (Lambda)               (None, 1)            0           pseudo-lum[0][0]                 \n",
      "                                                                 K_mag[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 971,581\n",
      "Trainable params: 971,569\n",
      "Non-trainable params: 12\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features = X.shape[1], X.shape[2]\n",
    "\n",
    "Global_model = SpectrumParallax(n_timesteps , n_features)\n",
    "\n",
    "Global_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assured-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 12s 59ms/step - loss: 2.2951 - mse: 2.2951 - val_loss: 2.3720 - val_mse: 2.3720\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.37199, saving model to Model1_13976spectra.h5\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 2.1824 - mse: 2.1824 - val_loss: 2.3700 - val_mse: 2.3700\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.37199 to 2.36997, saving model to Model1_13976spectra.h5\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 9s 53ms/step - loss: 2.3188 - mse: 2.3188 - val_loss: 2.0681 - val_mse: 2.0681\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.36997 to 2.06805, saving model to Model1_13976spectra.h5\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 12s 66ms/step - loss: 2.3827 - mse: 2.3827 - val_loss: 2.1458 - val_mse: 2.1458\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.06805\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 10s 54ms/step - loss: 1.9855 - mse: 1.9855 - val_loss: 2.0002 - val_mse: 2.0002\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.06805 to 2.00025, saving model to Model1_13976spectra.h5\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 2.1576 - mse: 2.1576 - val_loss: 2.2176 - val_mse: 2.2176\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.00025\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 2.1665 - mse: 2.1665 - val_loss: 2.0057 - val_mse: 2.0057\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.00025\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 2.2707 - mse: 2.2707 - val_loss: 2.0912 - val_mse: 2.0912\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.00025\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 2.2610 - mse: 2.2610 - val_loss: 2.2092 - val_mse: 2.2092\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.00025\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 2.2079 - mse: 2.2079 - val_loss: 2.1407 - val_mse: 2.1407\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.00025\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 2.2190 - mse: 2.2190 - val_loss: 2.0903 - val_mse: 2.0903\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.00025\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 2.1957 - mse: 2.1957 - val_loss: 2.0866 - val_mse: 2.0866\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.00025\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 2.2921 - mse: 2.2921 - val_loss: 2.0982 - val_mse: 2.0982\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.00025\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 2.2257 - mse: 2.2257 - val_loss: 2.1339 - val_mse: 2.1339\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.00025\n",
      "Epoch 15/20\n",
      "150/175 [========================>.....] - ETA: 1s - loss: 2.3478 - mse: 2.3478"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-07644660fc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m Global_model.fit([X, K_mag], Y,epochs=20, \n\u001b[0;32m----> 9\u001b[0;31m                  batch_size=64, verbose=1, shuffle=\"batch\" ,callbacks=callbacks,validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/astroML-python37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_loss', patience=50, verbose=1, min_delta=1e-7)\n",
    "checkpoint = ModelCheckpoint('Model1_13976spectra.h5', monitor='val_loss', \n",
    "                             verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, verbose=1, patience=5, min_lr=0.000000001)\n",
    "\n",
    "callbacks=[reduce_lr, checkpoint, earlystopper]\n",
    "\n",
    "Global_model.fit([X, K_mag], Y,epochs=20, \n",
    "                 batch_size=64, verbose=1, shuffle=\"batch\" ,callbacks=callbacks,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-contemporary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
